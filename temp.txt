python -m venv venv
source venv/Scripts/activate

python3 -m venv .venv
source .venv/bin/activate


pip install --upgrade pip
pip install tqdm notebook==7.1.2 openai elasticsearch pandas scikit-learn

docker run -it \
    --rm \
    --name elasticsearch \
    -p 9200:9200 \
    -p 9300:9300 \
    -e "discovery.type=single-node" \
    -e "xpack.security.enabled=false" \
    docker.elastic.co/elasticsearch/elasticsearch:8.4.3


export OPENAI_API_KEY=$(cat .openai_api_key)
echo $OPENAI_API_KEY

jupyter notebook

git config --global user.email "borowiec.k@gmail.com"
git config --global user.name "Konrad Borowiec"

ssh-keygen -t ed25519 -C "borowiec.k@gmail.com"
ssh-add ~/.ssh/id_ed25519
cat ~/.ssh/id_ed25519.pub
git remote set-url origin git@github.com:KonuTech/llm-zoomcamp.git



To update repo:
git fetch upstream
git checkout main
git merge upstream/main


curl -fsSL https://ollama.com/install.sh | sh

ollama start
ollama serve phi3
127.0.0.1:11434



user@DESKTOP-D7SFLUT:~$ curl -fsSL https://ollama.com/install.sh | sh
>>> Downloading ollama...
######################################################################## 100.0%##O#-#
>>> Installing ollama to /usr/local/bin...
>>> Creating ollama user...
>>> Adding ollama user to render group...
>>> Adding ollama user to video group...
>>> Adding current user to ollama group...
>>> Creating ollama systemd service...
>>> Enabling and starting ollama service...
Created symlink /etc/systemd/system/default.target.wants/ollama.service â†’ /etc/systemd/system/ollama.service.                                                               >>> Nvidia GPU detected.
>>> The Ollama API is now available at 127.0.0.1:11434.                                                                                                                     >>> Install complete. Run "ollama" from the command line.                                                                                                                   user@DESKTOP-D7SFLUT:~$



docker run -it \
    -v ollama:/root/.ollama \
    -p 11434:11434 \
    --name ollama \
    ollama/ollama



cd 02-open-source
docker-compose up
docker exec -it ollama bash
ollama pull phi3
ollama pull gemma:2b
{"schemaVersion":2,"mediaType":"application/vnd.docker.distribution.manifest.v2+json","config":{"mediaType":"application/vnd.docker.container.image.v1+json","digest":"sha256:887433b89a901c156f7e6944442f3c9e57f3c55d6ed52042cbb7303aea994290","size":483},"layers":[{"mediaType":"application/vnd.ollama.image.model","digest":"sha256:c1864a5eb19305c40519da12cc543519e48a0697ecd30e15d5ac228644957d12","size":1678447520},{"mediaType":"application/vnd.ollama.image.license","digest":"sha256:097a36493f718248845233af1d3fefe7a303f864fae13bc31a3a9704229378ca","size":8433},{"mediaType":"application/vnd.ollama.image.template","digest":"sha256:109037bec39c0becc8221222ae23557559bc594290945a2c4221ab4f303b8871","size":136},{"mediaType":"application/vnd.ollama.image.params","digest":"sha256:22a838ceb7fb22755a3b0ae9b4eadde629d19be1f651f73efb8c6b4e2cd0eea0","size":84}]}

mkdir ollama_files
docker run -it \
    --rm \
    -v ./ollama_files:/root/.ollama \
    -p 11434:11434 \
    --name ollama \
    ollama/ollama

docker exec -it ollama ollama pull gemma:2b
docker exec -it ollama ollama run gemma:2b
docker build -t ollama-gemma2b .
docker run -it --rm -p 11434:11434 ollama-gemma2b

docker run -it \
    --rm \
    -v ./ollama_files:/root/.ollama \
    -p 11435:11435 \
    --name ollama \
    ollama/ollama

Dockerfile:
docker build -t ollama-gemma2b .
docker run -it --rm -p 11435:11435 ollama-gemma2b


