{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a8154c5-b2e9-4225-a846-759f5030f2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\konutech\\llm-zoomcamp\\llm-zoomcamp\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaf6c5b0-c3a7-4f2e-934d-7cd03690fdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50475888-30bd-4f6b-b8e4-24fe3bcd889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9037f16d-8dad-4d3d-8d41-c16b3aa3bdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eb39e56-c1c5-4c75-bad4-0cdf4d04d760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d0d48e0-449e-453b-9e82-c789432bb3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"documents.json\", \"rt\") as f_in:\n",
    "    docs_raw = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9c0a7ae-a453-4a2f-a2ff-c77283be8476",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict[\"documents\"]:\n",
    "        doc[\"course\"] = course_dict[\"course\"]\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "238f151f-6112-45d9-865c-ca8a567f65b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccbd91e3-ac65-416b-98a2-6902ee63ba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'The course has already started, can I still enroll?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5c62bcf-c51f-46ad-afc2-81bae1a3e0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=[\n",
    "        \"question\",\n",
    "        \"text\",\n",
    "        \"section\"\n",
    "    ],\n",
    "    keyword_fields=[\n",
    "        \"course\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5ce211d-3212-456e-9b61-b117c9ce5e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x1263a63d550>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f18fc088-90e2-48ba-9146-7e161d815d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I still join the course after the start date?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I follow the course after it finishes?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - When will the course start?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - What can I do before the course starts?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'Yes, the slack channel remains open and you can ask questions there. But always sDocker containers exit code w search the channel first and second, check the FAQ (this document), most likely all your questions are already answered here.\\nYou can also tag the bot @ZoomcampQABot to help you conduct the search, but don’t rely on its answers 100%, it is pretty good though.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I get support if I take the course in the self-paced mode?',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost = {\n",
    "    \"question\": 3.0,\n",
    "    \"section\": 0.5\n",
    "}\n",
    "\n",
    "results = index.search(\n",
    "    filter_dict={\n",
    "        \"course\": \"data-engineering-zoomcamp\"\n",
    "    },\n",
    "    query=q,\n",
    "    boost_dict=boost,\n",
    "    num_results=5\n",
    ")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a7e7d15-136d-48aa-8efc-5b90db993c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33ec78f9-eb28-413d-ada1-46ccd111e24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The course has already started, can I still enroll?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f852c57-2ccd-4591-a94a-ccf47df0e1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    # model=\"gpt-4o\",\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": q\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "862634a2-5e26-40b5-9b73-655e7c1bc236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It depends on the policies of the institution or organization offering the course. Some may allow late enrollment for a certain period of time, while others may have strict enrollment deadlines. You should contact the course instructor or administration to inquire about the possibility of enrolling after the course has started.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dae2366-6503-47a2-818f-beceaa6f0de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database. Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "If the CONTEXT does not contain the answer, output NONE.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: {context}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f0df108-281d-44d5-9db2-b96e25ec15d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\n",
    "\n",
    "for doc in results:\n",
    "    context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33f83bfb-511c-432e-8a57-81a9fc030d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(\n",
    "    question=q,\n",
    "    context=context\n",
    ").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19cea11b-8be0-4ff9-8c03-9478f6fa7b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database. Use only the facts from the CONTEXT when answering the QUESTION.\n",
      "If the CONTEXT does not contain the answer, output NONE.\n",
      "\n",
      "QUESTION: The course has already started, can I still enroll?\n",
      "\n",
      "CONTEXT: section: General course-related questions\n",
      "question: Course - Can I still join the course after the start date?\n",
      "answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - What can I do before the course starts?\n",
      "answer: You can start by installing and setting up all the dependencies and requirements:\n",
      "Google cloud account\n",
      "Google Cloud SDK\n",
      "Python 3 (installed with Anaconda)\n",
      "Terraform\n",
      "Git\n",
      "Look over the prerequisites and syllabus to see if you are comfortable with these subjects.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I get support if I take the course in the self-paced mode?\n",
      "answer: Yes, the slack channel remains open and you can ask questions there. But always sDocker containers exit code w search the channel first and second, check the FAQ (this document), most likely all your questions are already answered here.\n",
      "You can also tag the bot @ZoomcampQABot to help you conduct the search, but don’t rely on its answers 100%, it is pretty good though.\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6d89526-daff-4606-9521-4c63bdcad071",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    # model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54bec6ac-8889-4ac6-a1dd-1b7298558ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, even if you don't register, you're still eligible to submit the homeworks. Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c796acfd-d0ba-40a5-8fb3-1bac41557ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {\n",
    "    \"question\": 3.0,\n",
    "    \"section\": 0.5\n",
    "    }\n",
    "    \n",
    "    results = index.search(\n",
    "        filter_dict={\n",
    "            \"course\": \"data-engineering-zoomcamp\"\n",
    "        },\n",
    "        query=query,\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4222759-fb0f-4d55-a03d-e8cef8bb5dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search(\"How do I run Kafka?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80ede216-f09d-47d0-89e9-7678de93c5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "    You are a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database. Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "    \n",
    "    QUESTION: {question}\n",
    "    \n",
    "    CONTEXT: {context}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "\n",
    "    prompt = prompt_template.format(\n",
    "        question=query,\n",
    "        context=context\n",
    "    ).strip()\n",
    "\n",
    "    # print(prompt)\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c19bf872-4360-406d-8295-da69b9dd3b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        # model=\"gpt-4o\",\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            \n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7631a1e0-bd5b-4125-86d0-cf8397f86af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'In the project directory, run:\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Java Kafka: How to run producer/consumer/kstreams/etc in terminal',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\\nTo create a virtual env and install packages (run only once)\\npython -m venv env\\nsource env/bin/activate\\npip install -r ../requirements.txt\\nTo activate it (you'll need to run it every time you need the virtual env):\\nsource env/bin/activate\\nTo deactivate it:\\ndeactivate\\nThis works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\\nAlso the virtual environment should be created only to run the python file. Docker images should first all be up and running.\",\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Module “kafka” not found when trying to run producer.py',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"Answer: To run the provided code, ensure that the 'dlt[duckdb]' package is installed. You can do this by executing the provided installation command: !pip install dlt[duckdb]. If you’re doing it locally, be sure to also have duckdb pip installed (even before the duckdb package is loaded).\",\n",
       "  'section': 'Workshop 1 - dlthub',\n",
       "  'question': 'How do I install the necessary dependencies to run the code?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'Run this command in terminal in the same directory (/docker/spark):\\nchmod +x build.sh',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Python Kafka: ./build.sh: Permission denied Error',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'According to https://github.com/dpkp/kafka-python/\\n“DUE TO ISSUES WITH RELEASES, IT IS SUGGESTED TO USE https://github.com/wbarnha/kafka-python-ng FOR THE TIME BEING”\\nUse pip install kafka-python-ng instead',\n",
       "  'section': 'Project',\n",
       "  'question': 'How to fix the error \"ModuleNotFoundError: No module named \\'kafka.vendor.six.moves\\'\"?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'If you have this error, it most likely that your kafka broker docker container is not working.\\nUse docker ps to confirm\\nThen in the docker compose yaml file folder, run docker compose up -d to start all the instances.',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'kafka.errors.NoBrokersAvailable: NoBrokersAvailable',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'Start a new terminal\\nRun: docker ps\\nCopy the CONTAINER ID of the spark-master container\\nRun: docker exec -it <spark_master_container_id> bash\\nRun: cat logs/spark-master.out\\nCheck for the log when the error happened\\nGoogle the error message from there',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Python Kafka: ./spark-submit.sh streaming.py - How to check why Spark master connection fails',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'You can check the version of your local spark using spark-submit --version. In the build.sh file of the Python folder, make sure that SPARK_VERSION matches your local version. Similarly, make sure the pyspark you pip installed also matches this version.',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'How do I check compatibility of local and container Spark versions?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'confluent-kafka: `pip install confluent-kafka` or `conda install conda-forge::python-confluent-kafka`\\nfastavro: pip install fastavro\\nAbhirup Ghosh\\nCan install Faust Library for Module 6 Python Version due to dependency conflicts?\\nThe Faust repository and library is no longer maintained - https://github.com/robinhood/faust\\nIf you do not know Java, you now have the option to follow the Python Videos 6.13 & 6.14 here https://www.youtube.com/watch?v=BgAlVknDFlQ&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=80  and follow the RedPanda Python version here https://github.com/DataTalksClub/data-engineering-zoomcamp/tree/main/06-streaming/python/redpanda_example - NOTE: I highly recommend watching the Java videos to understand the concept of streaming but you can skip the coding parts - all will become clear when you get to the Python videos and RedPanda files.',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Python Kafka: Installing dependencies for python3 06-streaming/python/avro_example/producer.py',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\\nHaving this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\\nYou will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\\nRemember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\\nThis is also a great resource: https://dangitgit.com/',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'How do I use Git / GitHub for this course?',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How do I run kafka?\"\n",
    "search_results = search(query)\n",
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f06abb8e-710c-4089-a53d-784ccba65222",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = build_prompt(query, search_results)\n",
    "answer = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a87e7093-886b-49ab-a232-11beadbc4b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To run Kafka, you can follow the specific instructions provided in the project directory. For Java Kafka, you would run the command `java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java`. For Python Kafka, you may need to create a virtual environment and run the requirements.txt and Python files in that environment.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7333098b-e1a3-483f-802d-223b72928333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01a51aaf-d386-4108-ab65-04ff485ae1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To run Kafka, you can use the command `java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java` in the project directory.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e1241fe-0ad1-477e-8193-a6f580d14100",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch(\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9cac7420-75cc-4aea-949f-50c57a0ee598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': '789ed2ad0aa4', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'IsB7FXuZTxGlHvf02lzFOw', 'version': {'number': '8.4.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '42f05b9372a9a4a470db3b52817899b99a76ee73', 'build_date': '2022-10-04T07:17:24.662462378Z', 'build_snapshot': False, 'lucene_version': '9.3.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a850c7e-94e8-447e-9005-7fcb1b6409fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7881e172-7cdf-40f9-8bf2-f0bf48450772",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"course-questions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c34973e9-dd69-4c53-aa1d-fa962df0a0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d470356f-7737-4e64-b631-1e4ddea48a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 948/948 [00:57<00:00, 16.43it/s]\n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e941451-3269-4745-ad52-16f4818a25fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'I just disovered the course. Can I still join it?'\n",
    "query = \"How do I run kafka?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "151d33be-44e4-4ce1-b499-b9322a286d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = {\n",
    "    \"size\": 5,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                    \"type\": \"best_fields\"\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"term\": {\n",
    "                    \"course\": \"data-engineering-zoomcamp\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83be4324-7813-4104-a019-3e9fb229294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = es_client.search(index=index_name, body=search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "21e4be0d-c90f-4854-875c-d366eb81db36",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_docs = []\n",
    "\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    result_docs.append(hit[\"_source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d1635f7-9a7f-46a3-94fb-82330cbec540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Answer: To run the provided code, ensure that the 'dlt[duckdb]' package is installed. You can do this by executing the provided installation command: !pip install dlt[duckdb]. If you’re doing it locally, be sure to also have duckdb pip installed (even before the duckdb package is loaded).\",\n",
       "  'section': 'Workshop 1 - dlthub',\n",
       "  'question': 'How do I install the necessary dependencies to run the code?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'In the project directory, run:\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Java Kafka: How to run producer/consumer/kstreams/etc in terminal',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\\nHaving this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\\nYou will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\\nRemember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\\nThis is also a great resource: https://dangitgit.com/',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'How do I use Git / GitHub for this course?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\\nTo create a virtual env and install packages (run only once)\\npython -m venv env\\nsource env/bin/activate\\npip install -r ../requirements.txt\\nTo activate it (you'll need to run it every time you need the virtual env):\\nsource env/bin/activate\\nTo deactivate it:\\ndeactivate\\nThis works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\\nAlso the virtual environment should be created only to run the python file. Docker images should first all be up and running.\",\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Module “kafka” not found when trying to run producer.py',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'You can check the version of your local spark using spark-submit --version. In the build.sh file of the Python folder, make sure that SPARK_VERSION matches your local version. Similarly, make sure the pyspark you pip installed also matches this version.',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'How do I check compatibility of local and container Spark versions?',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ffe16be-5a8d-4638-9ce0-5026c1e91609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"data-engineering-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    \n",
    "    result_docs = []\n",
    "\n",
    "    for hit in response[\"hits\"][\"hits\"]:\n",
    "        result_docs.append(hit[\"_source\"])\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3767b6f6-55da-4df2-8eb1-c9a2d6e1cd5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Answer: To run the provided code, ensure that the 'dlt[duckdb]' package is installed. You can do this by executing the provided installation command: !pip install dlt[duckdb]. If you’re doing it locally, be sure to also have duckdb pip installed (even before the duckdb package is loaded).\",\n",
       "  'section': 'Workshop 1 - dlthub',\n",
       "  'question': 'How do I install the necessary dependencies to run the code?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'In the project directory, run:\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Java Kafka: How to run producer/consumer/kstreams/etc in terminal',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\\nHaving this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\\nYou will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\\nRemember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\\nThis is also a great resource: https://dangitgit.com/',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'How do I use Git / GitHub for this course?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\\nTo create a virtual env and install packages (run only once)\\npython -m venv env\\nsource env/bin/activate\\npip install -r ../requirements.txt\\nTo activate it (you'll need to run it every time you need the virtual env):\\nsource env/bin/activate\\nTo deactivate it:\\ndeactivate\\nThis works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\\nAlso the virtual environment should be created only to run the python file. Docker images should first all be up and running.\",\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Module “kafka” not found when trying to run producer.py',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'You can check the version of your local spark using spark-submit --version. In the build.sh file of the Python folder, make sure that SPARK_VERSION matches your local version. Similarly, make sure the pyspark you pip installed also matches this version.',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'How do I check compatibility of local and container Spark versions?',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2ad3db92-ee3e-4479-9fc1-709a18a03c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = elastic_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e3e8d2f8-886d-4f16-9c01-23a04a12abee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To run Kafka producers, consumers, kstreams, etc in terminal, you need to navigate to the project directory and run the command: `java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java`. This will allow you to run the necessary Kafka components in the terminal.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11988ff-d827-4ac2-8f71-c8ce79d4b9e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
